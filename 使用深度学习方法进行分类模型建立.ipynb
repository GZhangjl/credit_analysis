{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.loadtxt(fname='companies.csv', delimiter=',', skiprows=1)\n",
    "# 以上是使用numpy进行数据导入代码，但是数据实际使用前需要重新编制数据指标，即重新形成数据features（在深度学习框架中，即inputs\n",
    "# 使用pandas导入数据形成DataFrame能够更方便处理数据\n",
    "# 数据导入\n",
    "\n",
    "companies_data = pd.read_excel(io='companies.xls', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASSET</th>\n",
       "      <th>LIBITY</th>\n",
       "      <th>CASSET</th>\n",
       "      <th>CLIBITY</th>\n",
       "      <th>CASH</th>\n",
       "      <th>SREVENUE</th>\n",
       "      <th>SPROFIT</th>\n",
       "      <th>NPROFIT</th>\n",
       "      <th>RECEIVAB</th>\n",
       "      <th>MAINCOST</th>\n",
       "      <th>INVENTRY</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>INTEREST</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.547336e+10</td>\n",
       "      <td>1.059925e+10</td>\n",
       "      <td>6.835456e+09</td>\n",
       "      <td>3.197114e+09</td>\n",
       "      <td>2.039102e+09</td>\n",
       "      <td>1.641898e+10</td>\n",
       "      <td>4.895354e+09</td>\n",
       "      <td>7.454865e+08</td>\n",
       "      <td>8.873680e+07</td>\n",
       "      <td>1.152363e+10</td>\n",
       "      <td>2.860091e+09</td>\n",
       "      <td>3.636876e+09</td>\n",
       "      <td>1.852834e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.680612e+10</td>\n",
       "      <td>3.970748e+10</td>\n",
       "      <td>2.085414e+10</td>\n",
       "      <td>1.668331e+10</td>\n",
       "      <td>1.289789e+10</td>\n",
       "      <td>3.511169e+09</td>\n",
       "      <td>1.814890e+09</td>\n",
       "      <td>7.598296e+08</td>\n",
       "      <td>2.265957e+09</td>\n",
       "      <td>1.696280e+09</td>\n",
       "      <td>8.692615e+08</td>\n",
       "      <td>1.561541e+09</td>\n",
       "      <td>7.700409e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.345341e+09</td>\n",
       "      <td>5.833393e+09</td>\n",
       "      <td>8.047869e+08</td>\n",
       "      <td>6.438295e+08</td>\n",
       "      <td>7.675127e+08</td>\n",
       "      <td>2.031876e+09</td>\n",
       "      <td>1.407197e+09</td>\n",
       "      <td>8.709336e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.246784e+08</td>\n",
       "      <td>2.157535e+08</td>\n",
       "      <td>4.623853e+08</td>\n",
       "      <td>2.280155e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.926957e+09</td>\n",
       "      <td>4.439096e+09</td>\n",
       "      <td>1.679505e+09</td>\n",
       "      <td>2.362389e+09</td>\n",
       "      <td>4.172194e+08</td>\n",
       "      <td>1.187910e+09</td>\n",
       "      <td>5.533089e+08</td>\n",
       "      <td>1.284279e+08</td>\n",
       "      <td>1.136382e+09</td>\n",
       "      <td>6.346015e+08</td>\n",
       "      <td>2.667839e+07</td>\n",
       "      <td>2.764960e+09</td>\n",
       "      <td>1.363481e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.596428e+10</td>\n",
       "      <td>6.573553e+10</td>\n",
       "      <td>3.248151e+10</td>\n",
       "      <td>3.089705e+10</td>\n",
       "      <td>3.929240e+09</td>\n",
       "      <td>2.166234e+10</td>\n",
       "      <td>2.408890e+09</td>\n",
       "      <td>9.145913e+08</td>\n",
       "      <td>2.869013e+09</td>\n",
       "      <td>1.925345e+10</td>\n",
       "      <td>6.586292e+09</td>\n",
       "      <td>1.765877e+10</td>\n",
       "      <td>8.996395e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.329863e+10</td>\n",
       "      <td>4.335956e+10</td>\n",
       "      <td>8.042116e+09</td>\n",
       "      <td>1.461258e+10</td>\n",
       "      <td>1.901062e+09</td>\n",
       "      <td>2.683185e+10</td>\n",
       "      <td>5.915800e+09</td>\n",
       "      <td>3.175083e+09</td>\n",
       "      <td>3.269928e+09</td>\n",
       "      <td>2.091605e+10</td>\n",
       "      <td>1.540905e+09</td>\n",
       "      <td>2.362876e+10</td>\n",
       "      <td>1.203785e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.873401e+09</td>\n",
       "      <td>5.393280e+09</td>\n",
       "      <td>5.699675e+08</td>\n",
       "      <td>2.341210e+09</td>\n",
       "      <td>5.593455e+08</td>\n",
       "      <td>8.910332e+08</td>\n",
       "      <td>5.780460e+08</td>\n",
       "      <td>3.555754e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.129872e+08</td>\n",
       "      <td>2.616537e+07</td>\n",
       "      <td>1.211009e+09</td>\n",
       "      <td>6.169577e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.432424e+10</td>\n",
       "      <td>1.666210e+10</td>\n",
       "      <td>1.041738e+10</td>\n",
       "      <td>7.579921e+09</td>\n",
       "      <td>2.737957e+09</td>\n",
       "      <td>1.753313e+10</td>\n",
       "      <td>1.162659e+09</td>\n",
       "      <td>7.667492e+08</td>\n",
       "      <td>5.307126e+07</td>\n",
       "      <td>1.637047e+10</td>\n",
       "      <td>4.213021e+09</td>\n",
       "      <td>4.756771e+09</td>\n",
       "      <td>2.423373e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.137729e+08</td>\n",
       "      <td>2.909524e+08</td>\n",
       "      <td>4.783448e+08</td>\n",
       "      <td>2.907972e+08</td>\n",
       "      <td>8.418496e+07</td>\n",
       "      <td>5.963979e+08</td>\n",
       "      <td>4.163151e+07</td>\n",
       "      <td>7.056628e+06</td>\n",
       "      <td>6.136065e+07</td>\n",
       "      <td>2.442264e+08</td>\n",
       "      <td>1.442264e+08</td>\n",
       "      <td>7.091970e+07</td>\n",
       "      <td>2.873910e+06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.707652e+10</td>\n",
       "      <td>1.169742e+10</td>\n",
       "      <td>2.196964e+09</td>\n",
       "      <td>1.447596e+09</td>\n",
       "      <td>7.088404e+08</td>\n",
       "      <td>1.102394e+09</td>\n",
       "      <td>6.967291e+08</td>\n",
       "      <td>5.776337e+08</td>\n",
       "      <td>1.136930e+09</td>\n",
       "      <td>4.056649e+08</td>\n",
       "      <td>2.384750e+07</td>\n",
       "      <td>8.292707e+08</td>\n",
       "      <td>4.089373e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASSET        LIBITY        CASSET       CLIBITY          CASH  \\\n",
       "0  1.547336e+10  1.059925e+10  6.835456e+09  3.197114e+09  2.039102e+09   \n",
       "1  5.680612e+10  3.970748e+10  2.085414e+10  1.668331e+10  1.289789e+10   \n",
       "2  8.345341e+09  5.833393e+09  8.047869e+08  6.438295e+08  7.675127e+08   \n",
       "3  7.926957e+09  4.439096e+09  1.679505e+09  2.362389e+09  4.172194e+08   \n",
       "4  9.596428e+10  6.573553e+10  3.248151e+10  3.089705e+10  3.929240e+09   \n",
       "5  6.329863e+10  4.335956e+10  8.042116e+09  1.461258e+10  1.901062e+09   \n",
       "6  7.873401e+09  5.393280e+09  5.699675e+08  2.341210e+09  5.593455e+08   \n",
       "7  2.432424e+10  1.666210e+10  1.041738e+10  7.579921e+09  2.737957e+09   \n",
       "8  8.137729e+08  2.909524e+08  4.783448e+08  2.907972e+08  8.418496e+07   \n",
       "9  1.707652e+10  1.169742e+10  2.196964e+09  1.447596e+09  7.088404e+08   \n",
       "\n",
       "       SREVENUE       SPROFIT       NPROFIT      RECEIVAB      MAINCOST  \\\n",
       "0  1.641898e+10  4.895354e+09  7.454865e+08  8.873680e+07  1.152363e+10   \n",
       "1  3.511169e+09  1.814890e+09  7.598296e+08  2.265957e+09  1.696280e+09   \n",
       "2  2.031876e+09  1.407197e+09  8.709336e+08  0.000000e+00  6.246784e+08   \n",
       "3  1.187910e+09  5.533089e+08  1.284279e+08  1.136382e+09  6.346015e+08   \n",
       "4  2.166234e+10  2.408890e+09  9.145913e+08  2.869013e+09  1.925345e+10   \n",
       "5  2.683185e+10  5.915800e+09  3.175083e+09  3.269928e+09  2.091605e+10   \n",
       "6  8.910332e+08  5.780460e+08  3.555754e+08  0.000000e+00  3.129872e+08   \n",
       "7  1.753313e+10  1.162659e+09  7.667492e+08  5.307126e+07  1.637047e+10   \n",
       "8  5.963979e+08  4.163151e+07  7.056628e+06  6.136065e+07  2.442264e+08   \n",
       "9  1.102394e+09  6.967291e+08  5.776337e+08  1.136930e+09  4.056649e+08   \n",
       "\n",
       "       INVENTRY          LOAN      INTEREST  RATING  \n",
       "0  2.860091e+09  3.636876e+09  1.852834e+08       1  \n",
       "1  8.692615e+08  1.561541e+09  7.700409e+07       1  \n",
       "2  2.157535e+08  4.623853e+08  2.280155e+07       1  \n",
       "3  2.667839e+07  2.764960e+09  1.363481e+08       1  \n",
       "4  6.586292e+09  1.765877e+10  8.996395e+08       1  \n",
       "5  1.540905e+09  2.362876e+10  1.203785e+09       1  \n",
       "6  2.616537e+07  1.211009e+09  6.169577e+07       1  \n",
       "7  4.213021e+09  4.756771e+09  2.423373e+08       1  \n",
       "8  1.442264e+08  7.091970e+07  2.873910e+06       3  \n",
       "9  2.384750e+07  8.292707e+08  4.089373e+07       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用深度学习算法放入进行分类，在这里尝试不再将按照五级分类法分成的结果在进行违约、非违约级的划分\n",
    "\n",
    "data = companies_data.drop(labels='RATING', axis=1)\n",
    "labels = companies_data['RATING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跳过探索性分析，直接进入指标编制阶段\n",
    "\n",
    "features = pd.DataFrame(columns=['x%s' % i for i in range(1,19)])\n",
    "features['x1'] = data['LIBITY'] / data['ASSET'] # 总负债/总资产\n",
    "features['x2'] = data['SREVENUE'] / data['INTEREST'] # 销售收入/利息费用\n",
    "features['x3'] = data['CASSET'] / data['CLIBITY'] # 流动资产/流动负债\n",
    "features['x4'] = data['NPROFIT'] / (data['ASSET'] - data['LIBITY']) # 净利润/净资产\n",
    "features['x5'] = data['SREVENUE'] / data['CASH'] # 销售收入/现金\n",
    "features['x6'] = np.log(data['ASSET']) # 总资产的对数\n",
    "features['x7'] = data['SREVENUE'] / data['ASSET'] # 销售收入/总资产\n",
    "features['x8'] = data['SPROFIT'] / data['ASSET'] # 销售利润/总资产\n",
    "features['x9'] = (data['SREVENUE'] - data['SPROFIT']) / data['SPROFIT'] # 销售成本/销售收入\n",
    "features['x10'] = (data['RECEIVAB'] + data['INVENTRY']) / (data['ASSET'] - data['LIBITY']) # (应收账款+存货)/净资产\n",
    "features['x11'] = data['INVENTRY'] / (data['ASSET'] - data['LIBITY']) # 存货/净资产\n",
    "features['x12'] = data['SREVENUE'] / data['LIBITY'] # 销售收入/总负债\n",
    "features['x13'] = data['CASSET'] / (data['ASSET'] - data['LIBITY']) # 流动资产/净资产\n",
    "features['x14'] = data['SPROFIT'] / data['INTEREST'] # 销售利润/利息费用\n",
    "features['x15'] = data['SREVENUE'] / data['CASSET'] # 销售收入/流动资产\n",
    "features['x16'] = data['SREVENUE'] / (data['ASSET'] - data['LIBITY']) # 销售收入/净资产\n",
    "features['x17'] = data['CASSET'] / data['INTEREST'] # 流动资产/利息费用\n",
    "features['x18'] = data['MAINCOST'] / data['SREVENUE'] # 主营业务成本/销售收入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>88.615529</td>\n",
       "      <td>2.138008</td>\n",
       "      <td>0.152948</td>\n",
       "      <td>8.052067</td>\n",
       "      <td>23.462385</td>\n",
       "      <td>1.061113</td>\n",
       "      <td>0.316373</td>\n",
       "      <td>2.353993</td>\n",
       "      <td>0.604998</td>\n",
       "      <td>0.586793</td>\n",
       "      <td>1.549070</td>\n",
       "      <td>1.402402</td>\n",
       "      <td>26.420905</td>\n",
       "      <td>2.402032</td>\n",
       "      <td>3.368613</td>\n",
       "      <td>36.891905</td>\n",
       "      <td>0.701848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699</td>\n",
       "      <td>45.597179</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.044438</td>\n",
       "      <td>0.272228</td>\n",
       "      <td>24.762910</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>0.934646</td>\n",
       "      <td>0.183361</td>\n",
       "      <td>0.050838</td>\n",
       "      <td>0.088426</td>\n",
       "      <td>1.219637</td>\n",
       "      <td>23.568743</td>\n",
       "      <td>0.168368</td>\n",
       "      <td>0.205348</td>\n",
       "      <td>270.818555</td>\n",
       "      <td>0.483110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699</td>\n",
       "      <td>89.111301</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.346716</td>\n",
       "      <td>2.647351</td>\n",
       "      <td>22.844969</td>\n",
       "      <td>0.243474</td>\n",
       "      <td>0.168621</td>\n",
       "      <td>0.443917</td>\n",
       "      <td>0.085891</td>\n",
       "      <td>0.085891</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.320384</td>\n",
       "      <td>61.714986</td>\n",
       "      <td>2.524738</td>\n",
       "      <td>0.808885</td>\n",
       "      <td>35.295269</td>\n",
       "      <td>0.307439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.560</td>\n",
       "      <td>8.712333</td>\n",
       "      <td>0.710935</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>2.847208</td>\n",
       "      <td>22.793535</td>\n",
       "      <td>0.149857</td>\n",
       "      <td>0.069801</td>\n",
       "      <td>1.146921</td>\n",
       "      <td>0.333459</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>0.481528</td>\n",
       "      <td>4.058060</td>\n",
       "      <td>0.707298</td>\n",
       "      <td>0.340584</td>\n",
       "      <td>12.317767</td>\n",
       "      <td>0.534217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685</td>\n",
       "      <td>24.078909</td>\n",
       "      <td>1.051282</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>5.513112</td>\n",
       "      <td>25.287242</td>\n",
       "      <td>0.225733</td>\n",
       "      <td>0.025102</td>\n",
       "      <td>7.992666</td>\n",
       "      <td>0.312792</td>\n",
       "      <td>0.217882</td>\n",
       "      <td>0.329538</td>\n",
       "      <td>1.074524</td>\n",
       "      <td>2.677616</td>\n",
       "      <td>0.666913</td>\n",
       "      <td>0.716614</td>\n",
       "      <td>36.105030</td>\n",
       "      <td>0.888798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1         x2        x3        x4        x5         x6        x7  \\\n",
       "0  0.685  88.615529  2.138008  0.152948  8.052067  23.462385  1.061113   \n",
       "1  0.699  45.597179  1.250000  0.044438  0.272228  24.762910  0.061810   \n",
       "2  0.699  89.111301  1.250000  0.346716  2.647351  22.844969  0.243474   \n",
       "3  0.560   8.712333  0.710935  0.036821  2.847208  22.793535  0.149857   \n",
       "4  0.685  24.078909  1.051282  0.030256  5.513112  25.287242  0.225733   \n",
       "\n",
       "         x8        x9       x10       x11       x12       x13        x14  \\\n",
       "0  0.316373  2.353993  0.604998  0.586793  1.549070  1.402402  26.420905   \n",
       "1  0.031949  0.934646  0.183361  0.050838  0.088426  1.219637  23.568743   \n",
       "2  0.168621  0.443917  0.085891  0.085891  0.348318  0.320384  61.714986   \n",
       "3  0.069801  1.146921  0.333459  0.007649  0.267602  0.481528   4.058060   \n",
       "4  0.025102  7.992666  0.312792  0.217882  0.329538  1.074524   2.677616   \n",
       "\n",
       "        x15       x16         x17       x18  \n",
       "0  2.402032  3.368613   36.891905  0.701848  \n",
       "1  0.168368  0.205348  270.818555  0.483110  \n",
       "2  2.524738  0.808885   35.295269  0.307439  \n",
       "3  0.707298  0.340584   12.317767  0.534217  \n",
       "4  0.666913  0.716614   36.105030  0.888798  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn库进行训练集、测试集分割\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.4, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预备工作完成，下面使用深度学习方法进行分类模型训练和测试\n",
    "# 使用mxnet作为深度学习框架\n",
    "\n",
    "from mxnet import gluon, init, nd, autograd\n",
    "from mxnet.gluon import loss as gloss, data as gdata, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 180\n",
    "\n",
    "train_set = gdata.ArrayDataset(nd.array(train_features), nd.array(train_labels))\n",
    "test_set = gdata.ArrayDataset(nd.array(test_features), nd.array(test_labels))\n",
    "train_iter = gdata.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_iter = gdata.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0., 0\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        y = y.astype('float32')\n",
    "        acc_sum += (y_hat.argmax(axis=1) == y-1).sum().asscalar()\n",
    "        n += y.size\n",
    "    return acc_sum / n\n",
    "    \n",
    "def train_display(net, train_iter, test_iter, loss, num_epochs, batch_size, trainer, params=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y-1).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y-1).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, test ass %.3f' % (epoch+1, train_l_sum / n, train_acc_sum / n, test_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型初始化\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(\n",
    "       nn.Dense(3, activation='relu'),  # 隐藏层\n",
    "       nn.Dense(5))                       # 输出层\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5000, loss 1.4848, train acc 0.424, test ass 0.429\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()   # 使用softmax -> cross entrophy来构建损失函数\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':0.000003})   # 使用梯度下降法进行反向传播\n",
    "num_epochs = 5000\n",
    "train_display(net=net, train_iter=train_iter, test_iter=test_iter, loss=loss, num_epochs=num_epochs, batch_size=batch_size, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于数据量太小，分类太多，结果并不好。使用机器学习算法效果更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据银保监会贷款风险分级，RATING共分为5级，现将标记为1、2的企业认定为非违约级，3、4、5认定为违约级\n",
    "\n",
    "labels_2 = pd.Series([0 if any([i ==1, i ==2]) else 1 for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_2, test_features_2, train_labels_2, test_labels_2 = train_test_split(features, labels_2, test_size=0.4, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2 = gdata.ArrayDataset(nd.array(train_features_2), nd.array(train_labels_2))\n",
    "test_set_2 = gdata.ArrayDataset(nd.array(test_features_2), nd.array(test_labels_2))\n",
    "train_iter_2 = gdata.DataLoader(train_set_2, batch_size=batch_size, shuffle=True)\n",
    "test_iter_2 = gdata.DataLoader(test_set_2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_2(data_iter, net):\n",
    "    acc_sum, n = 0., 0\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        y = y.astype('float32')\n",
    "        acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "        n += y.size\n",
    "    return acc_sum / n\n",
    "    \n",
    "def train_display_2(net, train_iter, test_iter, loss, num_epochs, batch_size, trainer, params=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy_2(test_iter, net)\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, test ass %.3f' % (epoch+1, train_l_sum / n, train_acc_sum / n, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2 = nn.Sequential()\n",
    "net_2.add(\n",
    "       nn.Dense(4, activation='relu'),  # 隐藏层\n",
    "       nn.Dense(5))                       # 输出层\n",
    "net_2.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10000, loss 0.2267, train acc 0.927, test ass 0.903\n"
     ]
    }
   ],
   "source": [
    "loss_2 = gloss.SoftmaxCrossEntropyLoss()   # 使用softmax -> cross entrophy来构建损失函数\n",
    "trainer_2 = gluon.Trainer(net_2.collect_params(), 'sgd', {'learning_rate':0.0003})   # 使用梯度下降法进行反向传播\n",
    "train_display_2(net=net_2, train_iter=train_iter_2, test_iter=test_iter_2, loss=loss_2, num_epochs=10000, batch_size=150, trainer=trainer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "# 隐藏层参数\n",
    "\n",
    "d0 = net_2[0]\n",
    "W0 = d0.weight.data()\n",
    "b0 = d0.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-8.2120271e-03  4.5904938e-02  2.1774584e-02 -4.1202935e-03\n",
      "   3.8836718e-02 -3.6159895e-02  2.7353175e-02  1.2638944e-02\n",
      "   2.3613335e-01  1.5638592e-03  6.9922456e-03  5.9595194e-02\n",
      "  -7.2111674e-03 -2.7258791e-02  2.0816064e-02 -4.1226018e-02\n",
      "   3.6391951e-02  1.0786835e-03]\n",
      " [-2.4935812e-02  2.5448151e-02 -6.1645498e-03  9.7552240e-03\n",
      "  -1.4685456e-01 -1.3761872e-03  7.2115827e-03  1.8842973e-02\n",
      "  -5.9175643e-04  3.6368889e-03  1.2858353e-02  8.5489126e-03\n",
      "   1.3014262e-02  1.2571070e-01  1.2007159e-02 -2.7220491e-02\n",
      "  -4.2778142e-02  2.5454203e-03]\n",
      " [-1.4670915e-02  4.8617937e-02  3.1142283e-02 -2.4586940e-02\n",
      "   7.0433840e-02 -5.1853709e-02  9.2192115e-03 -5.2540964e-03\n",
      "   3.1222349e-01  2.3328101e-03  3.5978624e-04  6.8734080e-02\n",
      "   3.2953839e-03 -7.4401774e-02  4.2218577e-02 -7.5513572e-02\n",
      "   5.5032920e-02 -5.5257785e-03]\n",
      " [ 4.5469955e-02  5.8949865e-02 -2.8883962e-02  3.5347531e-03\n",
      "   1.2122229e-02  4.7161183e-01  6.4882934e-03 -5.1686545e-03\n",
      "  -1.5377499e-01  2.0562587e-03  1.8655118e-02 -4.7524631e-02\n",
      "  -9.0206200e-03  1.3145155e-01 -2.4132658e-02  6.5078288e-02\n",
      "   8.7451480e-02  1.5499581e-03]]\n",
      "<NDArray 4x18 @cpu(0)> \n",
      "[0.00702984 0.00226986 0.0087001  0.01130816]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(W0, b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出层\n",
    "\n",
    "d1 = net_2[1]\n",
    "W1 = d1.weight.data()\n",
    "b1 = d1.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-0.07778171 -0.1129759  -0.09522577  0.4023443 ]\n",
      " [ 0.10366192  0.11382196  0.15748496  0.15435159]\n",
      " [-0.01133155 -0.00135357 -0.00852243 -0.17531666]\n",
      " [ 0.00869439  0.00549644  0.00360114 -0.18186778]\n",
      " [-0.00501886 -0.00505365 -0.00097281 -0.17796955]]\n",
      "<NDArray 5x4 @cpu(0)> \n",
      "[ 0.0926943  -0.0214239  -0.02455131 -0.02287426 -0.02384446]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(W1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2.save_parameters('./parameters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon]",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
